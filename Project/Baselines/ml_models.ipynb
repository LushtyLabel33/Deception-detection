{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - 2 : Classical ML Models\n",
    "\n",
    "For the classical Ml Models baseline, we have implemented and tested the dataset on various models which includes logistic regression, support vector machines, k-nearest neighbors, decision trees, and random forests. Taking inspiration from the ACL 2020 Diplomacy paper which used Logistic Regression, we extended the approach by using other ML models as well. We have used the same evaluation metrics : Accuracy, Macro F1 and Lie F1 score as given the paper so that we can have a proper comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_class:\n",
    "    def __init__(self, file_path, label_type=\"sender\"):\n",
    "        self.file_path = file_path\n",
    "        self.label_type = label_type.lower() \n",
    "        self.data = None\n",
    "        self.aggregated_messages = None\n",
    "\n",
    "    def load_data(self):\n",
    "        with jsonlines.open(self.file_path, 'r') as reader:\n",
    "            self.data = list(reader)\n",
    "        return self.data\n",
    "    \n",
    "    def process_dialog(self, dialog):\n",
    "        messages = dialog.get('messages', [])\n",
    "        senders = dialog.get('sender_labels', [])\n",
    "        receivers = dialog.get('receiver_labels', [])\n",
    "        return [{'message': msg, 'sender': senders[i], 'receiver': receivers[i]}  for i, msg in enumerate(messages)]\n",
    "    \n",
    "    def aggregate_dialogs(self):\n",
    "        if self.data is None:self.load_data()\n",
    "        return [msg for dialog in self.data for msg in self.process_dialog(dialog)]\n",
    "    \n",
    "    def aggregate_data(self):\n",
    "        self.aggregated_messages = self.aggregate_dialogs()\n",
    "        return self.aggregated_messages\n",
    "    \n",
    "    def to_bool(self, label):\n",
    "        return label if isinstance(label, bool) else (True if label.lower() == 'true' else False)\n",
    "    \n",
    "    def is_valid_label(self, label):\n",
    "        return label in {True, False, 'true', 'false'}\n",
    "    \n",
    "    def filter_message(self, msg):\n",
    "        if self.is_valid_label(msg.get('receiver')):\n",
    "            return { 'message': msg['message'],'sender': self.to_bool(msg['sender']), 'receiver': self.to_bool(msg['receiver'])}\n",
    "        return None\n",
    "\n",
    "    def filter_valid_messages(self):\n",
    "        if self.aggregated_messages is None: self.aggregate_data()\n",
    "        return [filtered for msg in self.aggregated_messages \n",
    "                if (filtered := self.filter_message(msg)) is not None]\n",
    "    \n",
    "    def get_text_and_labels(self):\n",
    "        valid_msgs = self.filter_valid_messages()\n",
    "        texts = [msg['message'] for msg in valid_msgs]\n",
    "        get_label = lambda msg: msg['sender'] if self.label_type == \"sender\" else msg['receiver']\n",
    "        labels = [0 if get_label(msg) else 1 for msg in valid_msgs]\n",
    "        return texts, labels\n",
    "\n",
    "    def vectorize_texts(self, texts, vectorizer=None):\n",
    "        if vectorizer is None:\n",
    "            vectorizer = CountVectorizer(stop_words='english')\n",
    "            X = vectorizer.fit_transform(texts)\n",
    "        else: X = vectorizer.transform(texts)\n",
    "        return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ml_Model_class:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_val, self.y_val = X_val, y_val\n",
    "        self.X_test, self.y_test = X_test, y_test\n",
    "\n",
    "    def fit_predict(self, model):\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model.predict(self.X_val), model.predict(self.X_test)\n",
    "\n",
    "    def compute_metrics(self, preds, y):\n",
    "        macro_f1 = lambda p, y_true: f1_score(y_true, p, average='macro', zero_division=0)\n",
    "        lie_f1   = lambda p, y_true: f1_score(y_true, p, pos_label=1, average='binary', zero_division=0)\n",
    "        acc      = lambda p, y_true: accuracy_score(y_true, p)\n",
    "        return { \"Macro F1\": macro_f1(preds, y), \"Lie F1\": lie_f1(preds, y), \"Accuracy\": acc(preds, y)}\n",
    "\n",
    "    def print_metrics(self, metrics, set_name):\n",
    "        formatted = {k: round(v, 3) for k, v in metrics.items()}\n",
    "        print(f\"{set_name}:\")\n",
    "        for key, value in formatted.items(): print(f\"  {key:<12}: {value}\")\n",
    "\n",
    "    def evaluate_model(self, model, model_name):\n",
    "        preds_val, preds_test = self.fit_predict(model)\n",
    "        metrics_test = self.compute_metrics(preds_test, self.y_test)\n",
    "        \n",
    "        print(model_name)\n",
    "        self.print_metrics(metrics_test, \"Test\")\n",
    "    \n",
    "    def logistic_regression(self):\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "        self.evaluate_model(model, \"Logistic Regression:\")\n",
    "\n",
    "    def svm(self):\n",
    "        model = SVC(class_weight='balanced')\n",
    "        self.evaluate_model(model, \"Support Vector Machine:\")\n",
    "\n",
    "    def knn(self):\n",
    "        model = KNeighborsClassifier()\n",
    "        self.evaluate_model(model, \"K-Nearest Neighbors:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/test.jsonl'\n",
    "val_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/validation.jsonl'\n",
    "test_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/test.jsonl'\n",
    "    \n",
    "train_set = Preprocessing_class(train_file, label_type=\"sender\")\n",
    "train_set.load_data()\n",
    "train_set.aggregate_data()\n",
    "train_texts, train_labels = train_set.get_text_and_labels()\n",
    "X_train, vectorizer = train_set.vectorize_texts(train_texts)\n",
    "    \n",
    "val_set = Preprocessing_class(val_file, label_type=\"sender\")\n",
    "val_set.load_data()\n",
    "val_set.aggregate_data()\n",
    "val_texts, val_labels = val_set.get_text_and_labels()\n",
    "X_val, _ = val_set.vectorize_texts(val_texts, vectorizer)\n",
    "\n",
    "test_set = Preprocessing_class(test_file, label_type=\"sender\")\n",
    "test_set.load_data()\n",
    "test_set.aggregate_data()\n",
    "test_texts, test_labels = test_set.get_text_and_labels()\n",
    "X_test, _ = test_set.vectorize_texts(test_texts, vectorizer)\n",
    "\n",
    "baseline_2 = Ml_Model_class(X_train, train_labels, X_val, val_labels, X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Test:\n",
      "  Macro F1    : 0.862\n",
      "  Lie F1      : 0.752\n",
      "  Accuracy    : 0.949\n",
      "Support Vector Machine:\n",
      "Test:\n",
      "  Macro F1    : 0.952\n",
      "  Lie F1      : 0.912\n",
      "  Accuracy    : 0.985\n",
      "K-Nearest Neighbors:\n",
      "Test:\n",
      "  Macro F1    : 0.537\n",
      "  Lie F1      : 0.116\n",
      "  Accuracy    : 0.92\n"
     ]
    }
   ],
   "source": [
    "baseline_2.logistic_regression()\n",
    "baseline_2.svm()\n",
    "baseline_2.knn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
