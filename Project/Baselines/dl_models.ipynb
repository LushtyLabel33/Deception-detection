{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, LSTM, GRU, Dense, Dropout\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - 3 : Deep Learning Models\n",
    "\n",
    "For the Deep Learning baseline, we have implemented and tested the dataset on 3 different types of models : RNNs, LSTMs and GRUs. Taking inspiration from the ACL 2020 Diplomacy paper which used LSTM, we extended the approach by using other DL models as well. The main concept is that we need some form of memory for the model to perform in a good manner. We have used the same evaluation metrics : Accuracy, Macro F1 and Lie F1 score as given the paper so that we can have a proper comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_class:\n",
    "    def __init__(self, file_path, label_type=\"sender\", num_words=10000, max_len=100):\n",
    "        self.file_path = file_path\n",
    "        self.label_type = label_type.lower() \n",
    "        self.num_words = num_words\n",
    "        self.max_len = max_len\n",
    "        self.data = None\n",
    "        self.aggregated_messages = None\n",
    "        self.tokenizer = Tokenizer(num_words=self.num_words, oov_token=\"<OOV>\")\n",
    "    \n",
    "    def load_data(self):\n",
    "        with jsonlines.open(self.file_path, 'r') as reader:\n",
    "            self.data = list(reader)\n",
    "        return self.data\n",
    "    \n",
    "    def process_dialog(self, dialog):\n",
    "        messages = dialog.get('messages', [])\n",
    "        senders = dialog.get('sender_labels', [])\n",
    "        receivers = dialog.get('receiver_labels', [])\n",
    "        return [{'message': msg, 'sender': senders[i], 'receiver': receivers[i]}\n",
    "            for i, msg in enumerate(messages)]\n",
    "    \n",
    "    def aggregate_dialogs(self):\n",
    "        if self.data is None:self.load_data()\n",
    "        return [msg for dialog in self.data for msg in self.process_dialog(dialog)]\n",
    "    \n",
    "    def aggregate_data(self):\n",
    "        self.aggregated_messages = self.aggregate_dialogs()\n",
    "        return self.aggregated_messages\n",
    "    \n",
    "    def to_bool(self, label):\n",
    "        return label if isinstance(label, bool) else (True if label.lower() == 'true' else False)\n",
    "    \n",
    "    def is_valid_label(self, label):\n",
    "        return label in {True, False, 'true', 'false'}\n",
    "    \n",
    "    def filter_message(self, msg):\n",
    "        if self.is_valid_label(msg.get('receiver')):\n",
    "            return {'message': msg['message'], 'sender': self.to_bool(msg['sender']), 'receiver': self.to_bool(msg['receiver'])}\n",
    "        return None\n",
    "    \n",
    "    def filter_valid_messages(self):\n",
    "        if self.aggregated_messages is None:\n",
    "            self.aggregate_data()\n",
    "        return [filtered for msg in self.aggregated_messages \n",
    "                if (filtered := self.filter_message(msg)) is not None]\n",
    "    \n",
    "    def get_text_and_labels(self):\n",
    "        valid_msgs = self.filter_valid_messages()\n",
    "        texts = [msg['message'] for msg in valid_msgs]\n",
    "        get_label = lambda msg: msg['sender'] if self.label_type == \"sender\" else msg['receiver']\n",
    "        labels = [0 if get_label(msg) else 1 for msg in valid_msgs]\n",
    "        return texts, labels\n",
    "\n",
    "    def tokenize_and_pad(self, texts):\n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded = pad_sequences(sequences, maxlen=self.max_len, padding='post', truncating='post')\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DL_model_class:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, vocab_size, max_len):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.X_val = X_val\n",
    "        self.y_val = np.array(y_val)\n",
    "        self.X_test = X_test\n",
    "        self.y_test = np.array(y_test)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build_model(self, cell_type=\"RNN\"):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(self.vocab_size, 64, input_length=self.max_len))\n",
    "        if cell_type == \"RNN\":\n",
    "            model.add(Bidirectional(SimpleRNN(64, return_sequences=False)))\n",
    "        elif cell_type == \"LSTM\":\n",
    "            model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "        elif cell_type == \"GRU\":\n",
    "            model.add(Bidirectional(GRU(64, return_sequences=False)))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def run_model(self, cell_type=\"RNN\", epochs=5, batch_size=32):\n",
    "        model = self.build_model(cell_type)\n",
    "        print(f\"\\nTraining {cell_type} model...\")\n",
    "        model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size,\n",
    "                  validation_data=(self.X_val, self.y_val), verbose=2)\n",
    "        print(f\"Evaluating {cell_type} model on test set...\")\n",
    "        loss, accuracy = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        preds = (model.predict(self.X_test) > 0.5).astype(\"int32\")\n",
    "        macro_f1 = f1_score(self.y_test, preds, average='macro', zero_division=0)\n",
    "        lie_f1 = f1_score(self.y_test, preds, pos_label=1, average='binary', zero_division=0)\n",
    "        print(f\"{cell_type} - Test Accuracy: {round(accuracy,3)}, Macro F1: {round(macro_f1,3)}, Lie F1: {round(lie_f1,3)}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    def run_birnn(self, epochs=5, batch_size=32):\n",
    "        self.run_model(cell_type=\"RNN\", epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def run_bilstm(self, epochs=5, batch_size=32):\n",
    "        self.run_model(cell_type=\"LSTM\", epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def run_bigru(self, epochs=5, batch_size=32):\n",
    "        self.run_model(cell_type=\"GRU\", epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/train.jsonl'\n",
    "val_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/validation.jsonl'\n",
    "test_file = '/Users/varun/Desktop/College/sem6/NLP/Group Project/Data/test.jsonl'\n",
    "\n",
    "train_set = Preprocessing_class(train_file, label_type=\"sender\", num_words=10000, max_len=100)\n",
    "train_set.load_data()\n",
    "train_set.aggregate_data()\n",
    "train_texts, train_labels = train_set.get_text_and_labels()\n",
    "X_train = train_set.tokenize_and_pad(train_texts)\n",
    "\n",
    "val_set = Preprocessing_class(val_file, label_type=\"sender\", num_words=10000, max_len=100)\n",
    "val_set.load_data()\n",
    "val_set.aggregate_data()\n",
    "val_texts, val_labels = val_set.get_text_and_labels()\n",
    "X_val = pad_sequences(train_set.tokenizer.texts_to_sequences(val_texts),maxlen=train_set.max_len, padding='post', truncating='post')\n",
    "\n",
    "test_class = Preprocessing_class(test_file, label_type=\"sender\", num_words=10000, max_len=100)\n",
    "test_class.load_data()\n",
    "test_class.aggregate_data()\n",
    "test_texts, test_labels = test_class.get_text_and_labels()\n",
    "X_test = pad_sequences(train_set.tokenizer.texts_to_sequences(test_texts),maxlen=train_set.max_len, padding='post', truncating='post')\n",
    "\n",
    "vocab_size = train_set.num_words\n",
    "\n",
    "baseline_3 = DL_model_class(X_train, train_labels, X_val, val_labels, X_test, test_labels, vocab_size, train_set.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN model...\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 - 6s - 17ms/step - accuracy: 0.9541 - loss: 0.2042 - val_accuracy: 0.9610 - val_loss: 0.1676\n",
      "Epoch 2/7\n",
      "376/376 - 6s - 17ms/step - accuracy: 0.9547 - loss: 0.1920 - val_accuracy: 0.9610 - val_loss: 0.1645\n",
      "Epoch 3/7\n",
      "376/376 - 6s - 17ms/step - accuracy: 0.9548 - loss: 0.1723 - val_accuracy: 0.9610 - val_loss: 0.1793\n",
      "Epoch 4/7\n",
      "376/376 - 6s - 16ms/step - accuracy: 0.9567 - loss: 0.1332 - val_accuracy: 0.9602 - val_loss: 0.2100\n",
      "Epoch 5/7\n",
      "376/376 - 6s - 16ms/step - accuracy: 0.9746 - loss: 0.0800 - val_accuracy: 0.9532 - val_loss: 0.2173\n",
      "Epoch 6/7\n",
      "376/376 - 6s - 16ms/step - accuracy: 0.9849 - loss: 0.0478 - val_accuracy: 0.9579 - val_loss: 0.3211\n",
      "Epoch 7/7\n",
      "376/376 - 6s - 16ms/step - accuracy: 0.9830 - loss: 0.0504 - val_accuracy: 0.9252 - val_loss: 0.3896\n",
      "Evaluating RNN model on test set...\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "RNN - Test Accuracy: 0.872, Macro F1: 0.503, Lie F1: 0.076\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_3.run_birnn(epochs=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 - 14s - 37ms/step - accuracy: 0.9538 - loss: 0.2025 - val_accuracy: 0.9610 - val_loss: 0.1617\n",
      "Epoch 2/7\n",
      "376/376 - 14s - 38ms/step - accuracy: 0.9548 - loss: 0.1745 - val_accuracy: 0.9602 - val_loss: 0.1649\n",
      "Epoch 3/7\n",
      "376/376 - 15s - 40ms/step - accuracy: 0.9595 - loss: 0.1349 - val_accuracy: 0.9470 - val_loss: 0.2007\n",
      "Epoch 4/7\n",
      "376/376 - 15s - 39ms/step - accuracy: 0.9686 - loss: 0.1034 - val_accuracy: 0.9454 - val_loss: 0.2295\n",
      "Epoch 5/7\n",
      "376/376 - 15s - 40ms/step - accuracy: 0.9732 - loss: 0.0866 - val_accuracy: 0.9564 - val_loss: 0.2832\n",
      "Epoch 6/7\n",
      "376/376 - 15s - 39ms/step - accuracy: 0.9801 - loss: 0.0648 - val_accuracy: 0.9299 - val_loss: 0.3464\n",
      "Epoch 7/7\n",
      "376/376 - 15s - 39ms/step - accuracy: 0.9830 - loss: 0.0545 - val_accuracy: 0.9392 - val_loss: 0.2766\n",
      "Evaluating LSTM model on test set...\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "LSTM - Test Accuracy: 0.891, Macro F1: 0.524, Lie F1: 0.106\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_3.run_bilstm(epochs=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GRU model...\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 - 15s - 40ms/step - accuracy: 0.9543 - loss: 0.2064 - val_accuracy: 0.9610 - val_loss: 0.1631\n",
      "Epoch 2/7\n",
      "376/376 - 15s - 40ms/step - accuracy: 0.9548 - loss: 0.1703 - val_accuracy: 0.9610 - val_loss: 0.1730\n",
      "Epoch 3/7\n",
      "376/376 - 16s - 41ms/step - accuracy: 0.9568 - loss: 0.1323 - val_accuracy: 0.9595 - val_loss: 0.1827\n",
      "Epoch 4/7\n",
      "376/376 - 16s - 43ms/step - accuracy: 0.9660 - loss: 0.1040 - val_accuracy: 0.9564 - val_loss: 0.2062\n",
      "Epoch 5/7\n",
      "376/376 - 15s - 41ms/step - accuracy: 0.9738 - loss: 0.0786 - val_accuracy: 0.9602 - val_loss: 0.2565\n",
      "Epoch 6/7\n",
      "376/376 - 15s - 41ms/step - accuracy: 0.9822 - loss: 0.0563 - val_accuracy: 0.9462 - val_loss: 0.3199\n",
      "Epoch 7/7\n",
      "376/376 - 15s - 41ms/step - accuracy: 0.9867 - loss: 0.0414 - val_accuracy: 0.9306 - val_loss: 0.3566\n",
      "Evaluating GRU model on test set...\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "GRU - Test Accuracy: 0.889, Macro F1: 0.523, Lie F1: 0.104\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_3.run_bigru(epochs=7, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
